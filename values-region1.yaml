# Region 1 Configuration

replicaCount: 3

serviceAccount:
  annotations:
    # a role that can access the S3 buckets
    eks.amazonaws.com/role-arn: arn:aws:iam::1234567890:role/my-role

env:
  # --------------------
  # common params
  # --------------------
  - name: RESTATE_LOG_FORMAT
    value: "json"
  - name: RESTATE_CLUSTER_NAME
    value: "two-region-demo-cluster"
  - name: RESTATE_METADATA_SERVER__TYPE
    value: "replicated"
  - name: RESTATE_DEFAULT_REPLICATION
    value: "{region: 2}"
  - name: RESTATE_BIFROST__DEFAULT_PROVIDER
    value: "replicated"
  - name: RESTATE_DEFAULT_NUM_PARTITIONS
    value: "128"
  - name: RESTATE_ROLES
    value: '["worker","admin","log-server","http-ingress"]'
  - name: RESTATE_ROCKSDB_TOTAL_MEMORY_SIZE
    value: "1024MB"
  - name: RESTATE_WORKER__SNAPSHOTS__SNAPSHOT_INTERVAL_NUM_RECORDS
    value: "10000"
  
  # until we have dynamodb multiregion metadata, we can use single region s3 metadata
  - name: RESTATE_METADATA_CLIENT__TYPE
    value: "object-store"
  - name: RESTATE_METADATA_CLIENT__PATH
    value: "s3://global-bucket/metadata"
  - name: RESTATE_METADATA_CLIENT__AWS_REGION
    # put the aws region of the global bucket here
    value: region1

  # --------------------
  # params that need to be overridden
  # --------------------
  - name: RESTATE_LOCATION
    value: region1
  # this needs to be an address all other nodes can resolve and reach
  # ie, a global route53 record pointing to an NLB created for each node
  - name: RESTATE_ADVERTISED_ADDRESS
    value: "http://$(RESTATE_NODE_NAME).two-region-demo-cluster.restate.region1.internal:5122"
  # both regions talk to their local bucket for snapshots, cross region replication copies them across
  - name: RESTATE_WORKER__SNAPSHOTS__DESTINATION
    value: "s3://region1-bucket/snapshots"